###############################################################################
# HDF5 Chunking Benchmark Suite - Merlin Specification
###############################################################################
#
# This Merlin workflow runs the HDF5 chunking benchmark suite on RZHound,
# distributing each configuration to a separate node for parallel execution.
#
# Usage:
#   # Generate parameter samples
#   merlin run chunking_benchmark.yaml --pgen pgen_configs.py
#
#   # Or run directly after samples are generated
#   merlin run chunking_benchmark.yaml
#
#   # Monitor status
#   merlin status chunking_benchmark.yaml
#
###############################################################################

description:
    name: hdf5_chunking_benchmark
    description: |
        HDF5 chunking strategy benchmark for exodus-py.
        Evaluates different HDF5 chunking configurations for large mesh transformations.
        Each configuration runs on a separate node for parallel execution.

batch:
    type: slurm
    bank: pbatch
    queue: pbatch

env:
    variables:
        # Output paths (on Lustre for performance)
        # Shared resources (mesh, venv) use fixed path
        OUTPUT_PATH: /p/lustre1/whitmore/chunking_benchmark_merlin
        # Per-run results and plots use workflow workspace
        RESULTS_DIR: $(MERLIN_WORKSPACE)/results
        PLOTS_DIR: $(MERLIN_WORKSPACE)/plots

        # Input mesh (generated in setup step)
        INPUT_MESH: $(OUTPUT_PATH)/input_mesh.exo

        # Mesh generation parameters
        NUM_NODES: 75000
        NUM_TIMESTEPS: 18500

        # Path to source scripts (in the spec directory)
        SCRIPT_DIR: $(SPECROOT)/..
        EXODUS_PY_DIR: $(SPECROOT)/../../..
        RUST_DIR: $(SPECROOT)/../../../..

        # Virtual environment path (shared across all steps)
        VENV_PATH: $(OUTPUT_PATH)/benchmark-venv

    labels:
        CACHE_MB: $(CACHE_MB)
        NODE_CHUNK: $(NODE_CHUNK_SIZE)
        ELEM_CHUNK: $(ELEMENT_CHUNK_SIZE)
        TIME_CHUNK: $(TIME_CHUNK_SIZE)
        PREEMPTION: $(PREEMPTION)

study:
    ###########################################################################
    # Step 1: Setup environment and install exodus-py from pre-built wheel
    ###########################################################################
    - name: setup
      description: Create venv, install pre-built exodus-py wheel, and setup directories
      run:
          cmd: |
              set -euo pipefail

              echo "Setting up benchmark environment..."
              echo "Working directory: $(pwd)"
              echo "Output path: $(OUTPUT_PATH)"

              # Create output directories
              mkdir -p $(OUTPUT_PATH)
              mkdir -p $(RESULTS_DIR)
              mkdir -p $(PLOTS_DIR)

              # Check for pre-built wheel
              WHEEL_DIR="$(RUST_DIR)/target/wheels"
              if [ ! -d "$WHEEL_DIR" ] || [ -z "$(ls -A $WHEEL_DIR/*.whl 2>/dev/null)" ]; then
                  echo "ERROR: No pre-built wheel found at $WHEEL_DIR"
                  echo "Please build exodus-py first:"
                  echo "  cd rust/exodus-py && ./install_and_test.sh"
                  exit 1
              fi

              # Create virtual environment if it doesn't exist
              if [ ! -d "$(VENV_PATH)" ]; then
                  echo "Creating virtual environment at $(VENV_PATH)..."
                  python3 -m venv $(VENV_PATH)
              fi

              # Activate venv
              source $(VENV_PATH)/bin/activate

              # Get Python version for wheel selection (e.g., cp312)
              PY_VERSION=$(python3 -c "import sys; print(f'cp{sys.version_info.major}{sys.version_info.minor}')")
              echo "Python wheel tag: $PY_VERSION"

              # Find the manylinux wheel for this Python version (prefer manylinux for portability)
              WHEEL_FILE=$(ls $WHEEL_DIR/exodus_py-*-${PY_VERSION}-*-manylinux*.whl 2>/dev/null | head -1)
              if [ -z "$WHEEL_FILE" ]; then
                  # Fall back to any wheel for this Python version
                  WHEEL_FILE=$(ls $WHEEL_DIR/exodus_py-*-${PY_VERSION}-*.whl 2>/dev/null | head -1)
              fi

              if [ -z "$WHEEL_FILE" ]; then
                  echo "ERROR: No wheel found for Python $PY_VERSION in $WHEEL_DIR"
                  echo "Available wheels:"
                  ls -la $WHEEL_DIR/*.whl
                  exit 1
              fi

              echo "Selected wheel: $WHEEL_FILE"

              # Check if exodus-py is already installed
              if ! pip show exodus-py > /dev/null 2>&1; then
                  echo "Installing exodus-py from wheel..."
                  pip install "$WHEEL_FILE"
              else
                  echo "exodus-py already installed"
              fi

              # Install benchmark dependencies
              pip install scipy matplotlib tqdm numpy

              # Verify exodus import
              python3 -c "import exodus; print(f'exodus-py version: {exodus.__version__}')"

              echo "Setup complete"
          nodes: 1
          procs: 1
          walltime: "00:30:00"

    ###########################################################################
    # Step 2: Generate the benchmark mesh
    ###########################################################################
    - name: generate_mesh
      description: Generate the ~100GB benchmark mesh on Lustre
      run:
          cmd: |
              set -euo pipefail

              echo "Generating benchmark mesh..."
              echo "Working directory: $(pwd)"

              # Activate venv
              source $(VENV_PATH)/bin/activate

              # Check if mesh already exists
              if [ -f "$(INPUT_MESH)" ]; then
                  echo "Mesh already exists: $(INPUT_MESH)"
                  ls -lh $(INPUT_MESH)
                  exit 0
              fi

              # Copy generate_mesh.py to working directory
              cp $(SCRIPT_DIR)/generate_mesh.py ./generate_mesh.py

              # Generate mesh
              python3 ./generate_mesh.py \
                  --output $(INPUT_MESH) \
                  --num-nodes $(NUM_NODES) \
                  --num-timesteps $(NUM_TIMESTEPS) \
                  --cache-mb 512 \
                  --node-chunk-size 25000 \
                  --element-chunk-size 25000 \
                  --time-chunk-size 100

              # Report file size
              echo "Mesh generated:"
              ls -lh $(INPUT_MESH)
          nodes: 1
          procs: 1
          walltime: "02:00:00"
          depends: [setup]

    ###########################################################################
    # Step 3: Run benchmark for each configuration (parameterized)
    ###########################################################################
    - name: run_benchmark
      description: Run mesh transformation benchmark with specific HDF5 config
      run:
          cmd: |
              set -euo pipefail

              echo "========================================================================"
              echo "Running benchmark configuration:"
              echo "  Cache MB:          $(CACHE_MB)"
              echo "  Node Chunk:        $(NODE_CHUNK_SIZE)"
              echo "  Element Chunk:     $(ELEMENT_CHUNK_SIZE)"
              echo "  Time Chunk:        $(TIME_CHUNK_SIZE)"
              echo "  Preemption:        $(PREEMPTION)"
              echo "  Working directory: $(pwd)"
              echo "========================================================================"

              # Activate venv
              source $(VENV_PATH)/bin/activate

              # Copy transform_mesh.py to working directory
              cp $(SCRIPT_DIR)/transform_mesh.py ./transform_mesh.py

              # Create unique output filenames
              CONFIG_STR="c$(CACHE_MB)_n$(NODE_CHUNK_SIZE)_e$(ELEMENT_CHUNK_SIZE)_t$(TIME_CHUNK_SIZE)_p$(PREEMPTION)"
              OUTPUT_MESH="$(RESULTS_DIR)/output_${CONFIG_STR}.exo"
              RESULT_JSON="$(RESULTS_DIR)/result_${CONFIG_STR}.json"

              # Run the transform
              python3 ./transform_mesh.py \
                  --input $(INPUT_MESH) \
                  --output "$OUTPUT_MESH" \
                  --cache-mb $(CACHE_MB) \
                  --node-chunk-size $(NODE_CHUNK_SIZE) \
                  --element-chunk-size $(ELEMENT_CHUNK_SIZE) \
                  --time-chunk-size $(TIME_CHUNK_SIZE) \
                  --preemption $(PREEMPTION) \
                  --output-json "$RESULT_JSON"

              # Cleanup output mesh to save space (keep only JSON results)
              rm -f "$OUTPUT_MESH"

              echo "Benchmark complete. Results saved to: $RESULT_JSON"
          nodes: 1
          procs: 1
          walltime: "02:00:00"
          depends: [generate_mesh]

    ###########################################################################
    # Step 4: Collect and aggregate results
    ###########################################################################
    - name: collect_results
      description: Aggregate all benchmark results into single JSON file
      run:
          cmd: |
              set -euo pipefail

              echo "Collecting benchmark results..."
              echo "Working directory: $(pwd)"

              # Activate venv
              source $(VENV_PATH)/bin/activate

              # Copy collector script to working directory
              cp $(SPECROOT)/collect_results.py ./collect_results.py

              # Run collector script
              python3 ./collect_results.py \
                  --results-dir $(RESULTS_DIR) \
                  --output $(RESULTS_DIR)/benchmark_results.json

              echo "Results collected: $(RESULTS_DIR)/benchmark_results.json"
          nodes: 1
          procs: 1
          walltime: "00:15:00"
          depends: [run_benchmark_*]

    ###########################################################################
    # Step 5: Generate plots and reports
    ###########################################################################
    - name: generate_plots
      description: Generate matplotlib visualizations from results
      run:
          cmd: |
              set -euo pipefail

              echo "Generating plots..."
              echo "Working directory: $(pwd)"

              # Activate venv
              source $(VENV_PATH)/bin/activate

              # Copy plot script to working directory
              cp $(SCRIPT_DIR)/plot_results.py ./plot_results.py

              # Generate plots
              python3 ./plot_results.py \
                  --results $(RESULTS_DIR)/benchmark_results.json \
                  --output-dir $(PLOTS_DIR)

              echo "Plots generated in: $(PLOTS_DIR)"

              # Print summary
              if [ -f "$(PLOTS_DIR)/benchmark_report.txt" ]; then
                  echo ""
                  echo "========================================================================"
                  echo "BENCHMARK SUMMARY"
                  echo "========================================================================"
                  cat $(PLOTS_DIR)/benchmark_report.txt
              fi
          nodes: 1
          procs: 1
          walltime: "00:30:00"
          depends: [collect_results]

###############################################################################
# Merlin Configuration
###############################################################################
# Note: Parameters (CACHE_MB, NODE_CHUNK_SIZE, etc.) are generated by
# pgen_configs.py when using --pgen flag. Do NOT define them in
# global.parameters as that conflicts with pgen-generated column_labels.
merlin:
    ###########################################################################
    # Sample generation via pgen
    ###########################################################################
    samples:
        generate:
            cmd: |
                python3 $(SPECROOT)/pgen_configs.py \
                    --outfile $(MERLIN_INFO)/samples.csv
        file: $(MERLIN_INFO)/samples.csv
        column_labels: [CACHE_MB, NODE_CHUNK_SIZE, ELEMENT_CHUNK_SIZE, TIME_CHUNK_SIZE, PREEMPTION]

    ###########################################################################
    # Resource configuration
    ###########################################################################
    resources:
        task_server: celery
        overlap: false
        workers:
            # Workers for the benchmark runs (can run many in parallel)
            benchmark_workers:
                args: -l INFO --concurrency 1 --prefetch-multiplier 1 -O fair
                steps: [run_benchmark]
                nodes: 1

            # Workers for serial tasks (setup, collect, plot)
            serial_workers:
                args: -l INFO --concurrency 1 --prefetch-multiplier 1 -O fair
                steps: [setup, generate_mesh, collect_results, generate_plots]
                nodes: 1
